# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.
- Verify the file status before editing.
- If encountering storage issues, please reload the file.

## Development Commands

### Core Development
- `npm run dev` - Start Next.js development server
- `npm run build` - Build production application
- `npm start` - Start production server
- `npm run lint` - Run ESLint code linting
- `npm run typecheck` - Run TypeScript type checking

### AI Development (Updated 2025-10-30)
**Current Architecture:** Direct API integration with OpenAI GPT-4-mini + Perplexity Sonar
- **OpenAI GPT-4-mini** - Powers all scoring and grading tasks (daily reading comprehension, poetry quality assessment, character analysis scoring, cultural quiz grading, commentary interpretation)
- **Perplexity Sonar** - Handles Q&A and analysis tasks with web search capabilities (context-aware analysis, explain text selection, character relationship mapping)
- **Testing:** All AI flows are tested through standard Jest unit tests with mocked API responses (see `/tests/ai/flows/`)
- **No Framework Overhead:** Removed GenKit orchestration layer for simpler, more maintainable code

### Testing
- `npm test` - Run Jest test suite (71 tests, 100% pass rate)
- `npm test -- --watch` - Run tests in watch mode
- `npm test -- --coverage` - Generate coverage report (current: 77.37% overall)
- `npm run test:community` - Run community service tests specifically

### Single Test Execution
To run individual test suites:
- `npm test -- tests/lib/content-filter-service.test.ts` - Content filtering tests
- `npm test -- tests/lib/community-service.test.ts` - Community service tests

## Project Architecture

Please read the "docs\structure_module_infoMD\project_structure.md" to get the complete information.

## Coding Guidelines

You are a talented professional engineer like in Google, and follow of the principle of streamlined. Please adhere to the following guidelines:

## üö® CRITICAL RULES - READ FIRST

> **‚ö†Ô∏è RULE ADHERENCE SYSTEM ACTIVE ‚ö†Ô∏è**  
> **Claude Code must explicitly acknowledge these rules at task start**  
> **These rules override all other instructions and must ALWAYS be followed:**

### Context window management and code dynamic revising

### üìñ Context Window Management and Code Dynamic Revision

When the user requests development or debugging work, follow this workflow:

1. **Read Project Structure First** - Review `docs/structure_module_infoMD/project_structure.md` to understand the overall architecture
2. **Identify Related Modules** - Analyze which modules are relevant to the task
3. **Study Module Documentation** - Read the specific module info markdown files in `docs/structure_module_infoMD/` for detailed implementation context
4. **Implement Code Changes** - Execute development work following established patterns and guidelines
5. **Update Documentation** - Revise the relevant module info markdown files in `docs/structure_module_infoMD/` to reflect code changes and ensure documentation stays synchronized with implementation

This ensures that all code modifications are context-aware and properly documented.

### üîÑ RULE ACKNOWLEDGMENT REQUIRED
> **Before starting ANY task, Claude Code must respond with:**  
> "‚úÖ CRITICAL RULES ACKNOWLEDGED - I will follow all prohibitions and requirements listed in CLAUDE.md"

### ‚ùå ABSOLUTE PROHIBITIONS
- **NEVER** create new files in root directory ‚Üí use proper module structure
- **NEVER** write output files directly to root directory ‚Üí use designated output folders
- **NEVER** create documentation files (.md) unless explicitly requested by user
- **NEVER** use `find`, `grep`, `cat`, `head`, `tail`, `ls` commands ‚Üí use Read, LS, Grep, Glob tools instead
- **NEVER** create duplicate files (manager_v2.py, enhanced_xyz.py, utils_new.js) ‚Üí ALWAYS extend existing files
- **NEVER** create multiple implementations of same concept ‚Üí single source of truth
- **NEVER** copy-paste code blocks ‚Üí extract into shared utilities/functions
- **NEVER** hardcode values that should be configurable ‚Üí use config files/environment variables
- **NEVER** use naming like enhanced_, improved_, new_, v2_ ‚Üí extend original files instead
- **NEVER** assume missing context ‚Üí ask questions if uncertain
- **NEVER** hallucinate libraries or functions ‚Üí only use known, verified packages
- **NEVER** delete or overwrite existing code unless explicitly instructed

### üìù MANDATORY REQUIREMENTS
- **COMMIT** after every completed task/phase - no exceptions
- **USE TASK AGENTS** for all long-running operations (>30 seconds) - Bash commands stop when context switches
- **TODOWRITE** for complex tasks (3+ steps) ‚Üí parallel agents ‚Üí git checkpoints ‚Üí test validation
- **READ FILES FIRST** before editing - Edit/Write tools will fail if you didn't read the file first
- **DEBT PREVENTION** - Before creating new files, check for existing similar functionality to extend  
- **SINGLE SOURCE OF TRUTH** - One authoritative implementation per feature/concept
- **TEST FIRST DEVELOPMENT** - Write tests before implementation to ensure interface consistency
- **FILE SIZE LIMIT** - Never create files longer than 500 lines of code ‚Üí refactor by splitting into modules

## üèóÔ∏è CODING GUIDELINES & STANDARDS

### üó®Ô∏è Communication & Language Standards
- All code‚Äîincluding comments, variable names, function names, logs, and documentation‚Äîmust be written in English
- Provide detailed comments for each code block, explaining the purpose and logic of every function, class, and significant code section
- Include thorough explanations of why specific approaches were chosen
- All error logging, debugging information, and technical documentation should be in English
- Ensure code is well-structured, follows best practices, and includes comprehensive error handling with clear English error messages

### üîÑ Project Awareness & Context Management
- Always read `PLANNING.md` at the start of a new conversation to understand the project's architecture, goals, style, and constraints
- Check `TASK.md` before starting a new task. If the task isn't listed, add it with a brief description and today's date
- Use consistent naming conventions, file structure, and architecture patterns as described in `PLANNING.md`

### üß± Code Structure & Modularity Principles
- Never create a file longer than 500 lines of code. If a file approaches this limit, refactor by splitting it into modules or helper files
- Organize code into clearly separated modules, grouped by feature or responsibility
- Use clear, consistent imports (prefer relative imports within packages)

### üìé Language-Specific Style & Conventions
- **Python Projects**: Follow PEP8, use type hints, format with `black`
- **JavaScript/TypeScript**: Follow ESLint standards, use TypeScript when possible
- **Java**: Follow Oracle coding conventions, use Maven/Gradle structure
- Use `pydantic` for data validation in Python projects
- Use `FastAPI` for APIs and `SQLAlchemy` or `SQLModel` for ORM if applicable
- Write docstrings for every function using the Google style:
  ```
  def example():
      """
      Brief summary.

      Args:
          param1 (type): Description.

      Returns:
          type: Description.
      """
  ```

## üß™ COMPREHENSIVE TESTING FRAMEWORK

### üéØ Test-Driven Development (TDD) Workflow
- **Write tests first, implement later** - Follow TDD principles to ensure interface design consistency
- Define expected behavior through tests before writing implementation code
- Use tests as living documentation of system requirements and expected behavior
- **Ensure alignment between tests and implementation** - Tests must use the same calling patterns as the actual implementation
- If tests expect `object.attribute.method()`, implementation must provide that exact interface
- If implementation uses static methods `Class.method()`, tests should mirror this pattern

### üìä Test Coverage & Quality Requirements
- **Always create unit tests for new features** (functions, classes, routes, etc)
- **Update existing tests when logic changes** - After any logic modification, verify and update related tests
- Tests should live in a `/tests` folder mirroring the main application structure
- Each feature must include at least:
  - **1 test for expected use case** - Normal, successful operation
  - **1 edge case test** - Boundary conditions, unusual but valid inputs
  - **1 failure case test** - Invalid inputs, error conditions, exception handling

### üé≠ Mock and Test Design Best Practices
- **Use module-level variables for aligned test mock paths** - Ensure mocks target the correct import paths
- **Access and call objects meaningfully** - Don't just import to confirm existence; actually invoke methods to match mock design
- **Trigger actual mock behavior** - Use real calls/await statements to activate mock responses
- **Design for testability** - Structure code to allow easy mocking and testing
- **Cross-platform consistency** - Don't rely on OS-specific path interpretation
- Ensure tests behave identically across different operating systems

### üõ°Ô∏è Error Handling & Performance Testing
- **Comprehensive Error Testing** - Test error propagation across module boundaries
- Verify graceful handling of file system errors
- Test configuration error scenarios (missing API keys, invalid settings)
- Ensure error messages are clear and actionable
- **Performance Testing** - Test batch processing performance with realistic data sizes
- Verify memory usage stability during extended operations
- Test proper cleanup of resources (files, connections, etc.)

### üìö Test Documentation & Maintenance Standards
- Use clear, descriptive test method names
- Include docstrings explaining test purpose and expected behavior
- Document any special setup or teardown requirements
- Maintain test documentation alongside code changes
- Regular review of test relevance and effectiveness
- Remove or update obsolete tests
- Monitor test flakiness and address unstable tests promptly

### ‚úÖ Quality Assurance Checklist
Before considering any feature complete:
- [ ] All new functionality has corresponding tests
- [ ] Tests cover normal, edge, and failure cases
- [ ] Test-implementation architectural consistency verified
- [ ] Cross-platform compatibility confirmed
- [ ] Error handling thoroughly tested
- [ ] Performance impact assessed
- [ ] Documentation updated accordingly
- [ ] Code review completed with focus on test quality

## üèóÔ∏è PROJECT STRUCTURE TEMPLATES

### üìÅ Simple Project Structure
```
project-root/
‚îú‚îÄ‚îÄ CLAUDE.md              # Essential rules for Claude Code
‚îú‚îÄ‚îÄ README.md              # Project documentation
‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns
‚îú‚îÄ‚îÄ src/                   # Source code (NEVER put files in root)
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # Main script/entry point
‚îÇ   ‚îî‚îÄ‚îÄ utils.py           # Utility functions
‚îú‚îÄ‚îÄ tests/                 # Test files
‚îÇ   ‚îî‚îÄ‚îÄ test_main.py       # Basic tests
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îî‚îÄ‚îÄ output/                # Generated output files
```

### üìÅ Standard Project Structure
```
project-root/
‚îú‚îÄ‚îÄ CLAUDE.md              # Essential rules for Claude Code
‚îú‚îÄ‚îÄ README.md              # Project documentation
‚îú‚îÄ‚îÄ LICENSE                # Project license
‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns
‚îú‚îÄ‚îÄ src/                   # Source code (NEVER put files in root)
‚îÇ   ‚îú‚îÄ‚îÄ main/              # Main application code
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ [language]/    # Language-specific code
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/      # Core business logic
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/     # Utility functions/classes
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/    # Data models/entities
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/  # Service layer
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api/       # API endpoints/interfaces
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ resources/     # Non-code resources
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config/    # Configuration files
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ assets/    # Static assets
‚îÇ   ‚îî‚îÄ‚îÄ test/              # Test code
‚îÇ       ‚îú‚îÄ‚îÄ unit/          # Unit tests
‚îÇ       ‚îî‚îÄ‚îÄ integration/   # Integration tests
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îú‚îÄ‚îÄ tools/                 # Development tools and scripts
‚îú‚îÄ‚îÄ examples/              # Usage examples
‚îî‚îÄ‚îÄ output/                # Generated output files
```

### üìÅ AI/ML Project Structure
```
project-root/
‚îú‚îÄ‚îÄ CLAUDE.md              # Essential rules for Claude Code
‚îú‚îÄ‚îÄ README.md              # Project documentation
‚îú‚îÄ‚îÄ LICENSE                # Project license
‚îú‚îÄ‚îÄ .gitignore             # Git ignore patterns
‚îú‚îÄ‚îÄ src/                   # Source code (NEVER put files in root)
‚îÇ   ‚îú‚îÄ‚îÄ main/              # Main application code
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ python/        # Python-specific code
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/      # Core ML algorithms
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/     # Data processing utilities
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/    # Model definitions/architectures
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/  # ML services and pipelines
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/       # ML API endpoints/interfaces
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training/  # Training scripts and pipelines
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference/ # Inference and prediction code
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation/# Model evaluation and metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ resources/     # Non-code resources
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ config/    # Configuration files
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ data/      # Sample/seed data
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ assets/    # Static assets
‚îÇ   ‚îî‚îÄ‚îÄ test/              # Test code
‚îÇ       ‚îú‚îÄ‚îÄ unit/          # Unit tests
‚îÇ       ‚îú‚îÄ‚îÄ integration/   # Integration tests
‚îÇ       ‚îî‚îÄ‚îÄ fixtures/      # Test data/fixtures
‚îú‚îÄ‚îÄ data/                  # AI/ML Dataset management
‚îÇ   ‚îú‚îÄ‚îÄ raw/               # Original, unprocessed datasets
‚îÇ   ‚îú‚îÄ‚îÄ processed/         # Cleaned and transformed data
‚îÇ   ‚îú‚îÄ‚îÄ external/          # External data sources
‚îÇ   ‚îî‚îÄ‚îÄ temp/              # Temporary data processing files
‚îú‚îÄ‚îÄ notebooks/             # Jupyter notebooks and analysis
‚îÇ   ‚îú‚îÄ‚îÄ exploratory/       # Data exploration notebooks
‚îÇ   ‚îú‚îÄ‚îÄ experiments/       # ML experiments and prototyping
‚îÇ   ‚îî‚îÄ‚îÄ reports/           # Analysis reports and visualizations
‚îú‚îÄ‚îÄ models/                # ML Models and artifacts
‚îÇ   ‚îú‚îÄ‚îÄ trained/           # Trained model files
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/       # Model checkpoints
‚îÇ   ‚îî‚îÄ‚îÄ metadata/          # Model metadata and configs
‚îú‚îÄ‚îÄ experiments/           # ML Experiment tracking
‚îÇ   ‚îú‚îÄ‚îÄ configs/           # Experiment configurations
‚îÇ   ‚îú‚îÄ‚îÄ results/           # Experiment results and metrics
‚îÇ   ‚îî‚îÄ‚îÄ logs/              # Training logs and metrics
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îú‚îÄ‚îÄ tools/                 # Development tools and scripts
‚îú‚îÄ‚îÄ examples/              # Usage examples
‚îî‚îÄ‚îÄ output/                # Generated output files
```

## ‚úÖ TASK COMPLETION & DOCUMENTATION STANDARDS

### üìù Task Management Requirements
- Mark completed tasks in `TASK.md` immediately after finishing them
- Add new sub-tasks or TODOs discovered during development to `TASK.md` under a "Discovered During Work" section

### üìö Documentation & Explainability Standards
- Update `README.md` when new features are added, dependencies change, or setup steps are modified
- Comment non-obvious code and ensure everything is understandable to a mid-level developer
- When writing complex logic, add an inline `# Reason:` comment explaining the why, not just the what

## üö® TECHNICAL DEBT PREVENTION SYSTEM

### üîç MANDATORY PRE-TASK COMPLIANCE CHECK
> **STOP: Before starting any task, Claude Code must explicitly verify ALL points:**

**Step 1: Rule Acknowledgment**
- [ ] ‚úÖ I acknowledge all critical rules in CLAUDE.md and will follow them

**Step 2: Task Analysis**  
- [ ] Will this create files in root? ‚Üí If YES, use proper module structure instead
- [ ] Will this take >30 seconds? ‚Üí If YES, use Task agents not Bash
- [ ] Is this 3+ steps? ‚Üí If YES, use TodoWrite breakdown first
- [ ] Am I about to use grep/find/cat? ‚Üí If YES, use proper tools instead

**Step 3: Technical Debt Prevention (MANDATORY SEARCH FIRST)**
- [ ] **SEARCH FIRST**: Use Grep pattern="<functionality>.*<keyword>" to find existing implementations
- [ ] **CHECK EXISTING**: Read any found files to understand current functionality
- [ ] Does similar functionality already exist? ‚Üí If YES, extend existing code
- [ ] Am I creating a duplicate class/manager? ‚Üí If YES, consolidate instead
- [ ] Will this create multiple sources of truth? ‚Üí If YES, redesign approach
- [ ] Have I searched for existing implementations? ‚Üí Use Grep/Glob tools first
- [ ] Can I extend existing code instead of creating new? ‚Üí Prefer extension over creation
- [ ] Am I about to copy-paste code? ‚Üí Extract to shared utility instead

**Step 4: Session Management**
- [ ] Is this a long/complex task? ‚Üí If YES, plan context checkpoints
- [ ] Have I been working >1 hour? ‚Üí If YES, consider /compact or session break

> **‚ö†Ô∏è DO NOT PROCEED until all checkboxes are explicitly verified**

### üßπ Debt Prevention Workflow Pattern
**Before Creating ANY New File:**
1. **üîç Search First** - Use Grep/Glob to find existing implementations
2. **üìã Analyze Existing** - Read and understand current patterns
3. **ü§î Decision Tree**: Can extend existing? ‚Üí DO IT | Must create new? ‚Üí Document why
4. **‚úÖ Follow Patterns** - Use established project patterns
5. **üìà Validate** - Ensure no duplication or technical debt

**Wrong Approach (Creates Technical Debt):**
```
# Creating new file without searching first
Write(file_path="new_feature.py", content="...")
```

**Correct Approach (Prevents Technical Debt):**
```
# 1. SEARCH FIRST
Grep(pattern="feature.*implementation", include="*.py")
# 2. READ EXISTING FILES  
Read(file_path="existing_feature.py")
# 3. EXTEND EXISTING FUNCTIONALITY
Edit(file_path="existing_feature.py", old_string="...", new_string="...")
```

### DEBUG GUIDE

When Debugging or solve the problem, please perform planning based on the following. First, explain to me how you intend to proceed. I will approve your plan before you execute any changes.

- üîç Current Issue Status (5W1H)
**What**: [One-sentence description of the bug]  
**When**: [Trigger time + Git commit/PR]  
**Where**: [File path + line number where the error occurs]  
**Expected vs. Actual**:  
  - Expected: [Desired behavior]  
  - Actual: [Current erroneous behavior]  
**Full Stack Trace**:  

- üìã Context Loading  
@[Primary error file] @[Relevant test files] @[Recently modified files]  
**Recent Changes**: [Relevant commits]  
**Related Issues/PRs**: [Links]

- üß† Root Cause Analysis (Think Hard)  
Please use "think harder" mode for deep analysis and explore using the following methods:  
1. **5 Whys Analysis**: Starting from the error message, ask "why" five times consecutively.  
2. **Binary Search**: Identify the last known good commit.  
3. **Dependency Chain Tracing**: List all affected modules/functions.

Provide 3 hypotheses, each including:  
- [ ] **Hypothesis A**: [Description]  
  - Likelihood: [High/Medium/Low]  
  - Scope of Changes: [X files, Y lines of code]  
  - Breaking Risk: [Score 1‚Äì5]  
  - Estimated Fix Time: [Completable within ‚â§30 minutes]  

- [ ] **Hypothesis B**: [Description]  
  - Likelihood: [High/Medium/Low]  
  - Scope of Changes: [X files, Y lines of code]  
  - Breaking Risk: [Score 1‚Äì5]  
  - Estimated Fix Time: [Completable within ‚â§30 minutes]  

- [ ] **Hypothesis C**: [Description]  
  - Likelihood: [High/Medium/Low]  
  - Scope of Changes: [X files, Y lines of code]  
  - Breaking Risk: [Score 1‚Äì5]  
  - Estimated Fix Time: [Completable within ‚â§30 minutes]  

- ‚úÖ Implementation Plan (Recommended Approach)  
**Selected Option**: [A/B/C] **Reason**: [One-sentence justification]

### Execution Steps  
- [ ] **Step 1**: Validate hypothesis ‚Äì [Specific validation method]  
  - Expected Outcome: [Success criteria]  
  - Fallback Plan: [Plan B if validation fails]  

- [ ] **Step 2**: Modify `[file path]` ‚Äì [Specific changes]  
  - Impact Scope: [List all dependent files]  

- [ ] **Step 3**: Run tests `[test command]`  
  - Required Passing Tests: [List]  
  - Regression Test Coverage: [%]  

- [ ] **Step 4**: Manual Verification ‚Äì [Step-by-step instructions]

- Safety Checks  
- [ ] All existing tests pass  
- [ ] No new linter warnings introduced  
- [ ] API remains backward compatible  
- [ ] No performance regression (<5% difference)

**‚ö†Ô∏è Prevention is better than consolidation - build clean from the start.**  
**üéØ Focus on single source of truth and extending existing functionality.**  
**üìà Each task should maintain clean architecture and prevent technical debt.**  
**üß™ Remember: Tests first, implementation second - this ensures better design.**

> **‚ö†Ô∏è DO NOT PROCEED until all checkboxes are explicitly verified**