[2025-11-20T03:10:59.279Z] [DEBUG] [PERPLEXITY_STREAMING] Starting async generator: perplexityRedChamberQAStreaming
DATA: {
  "functionName": "perplexityRedChamberQAStreaming",
  "inputType": "object",
  "inputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ],
  "hasAsyncIterator": false
}
[2025-11-20T03:10:59.310Z] [DEBUG] [PERPLEXITY_STREAMING] Function entry point reached
DATA: {
  "inputType": "object",
  "inputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ],
  "userQuestionLength": 114,
  "enableStreaming": true
}
[2025-11-20T03:10:59.774Z] [DEBUG] [PERPLEXITY_STREAMING] Getting Perplexity client
[2025-11-20T03:10:59.784Z] [DEBUG] [PERPLEXITY_STREAMING] Client obtained
DATA: {
  "clientType": "object",
  "clientConstructor": "PerplexityClient",
  "hasStreamingMethod": true
}
[2025-11-20T03:10:59.788Z] [DEBUG] [PERPLEXITY_STREAMING] Calling client.streamingCompletionRequest
DATA: {
  "processedInputType": "object",
  "processedInputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ]
}
[2025-11-20T03:10:59.792Z] [DEBUG] [PERPLEXITY_STREAMING] Stream generator created
DATA: {
  "generatorType": "object",
  "generatorConstructor": "",
  "hasAsyncIterator": true
}
[2025-11-20T03:10:59.796Z] [DEBUG] [PERPLEXITY_STREAMING] Starting for-await loop on: client.streamingCompletionRequest
DATA: {
  "iterableSource": "client.streamingCompletionRequest",
  "iterableType": "object",
  "hasAsyncIterator": true,
  "hasIterator": false,
  "constructorName": ""
}
[2025-11-20T03:10:59.799Z] [DEBUG] [PERPLEXITY_CLIENT] PerplexityClient.streamingCompletionRequest called
DATA: {
  "inputType": "object",
  "userQuestionLength": 114,
  "enableStreaming": true
}
[2025-11-20T03:10:59.803Z] [DEBUG] [PERPLEXITY_CLIENT] Making HTTP request to Perplexity API (native fetch)
DATA: {
  "endpoint": "https://api.perplexity.ai/chat/completions",
  "requestDataKeys": [
    "model",
    "temperature",
    "max_tokens",
    "stream",
    "reasoning_effort",
    "messages"
  ],
  "model": "sonar-reasoning",
  "stream": true
}
[2025-11-20T03:11:01.589Z] [DEBUG] [PERPLEXITY_CLIENT] Received HTTP response (native fetch)
DATA: {
  "statusCode": 200,
  "statusText": "OK",
  "hasBody": true,
  "contentType": "text/event-stream; charset=utf-8"
}
[2025-11-20T03:32:15.399Z] [DEBUG] [PERPLEXITY_STREAMING] Starting async generator: perplexityRedChamberQAStreaming
DATA: {
  "functionName": "perplexityRedChamberQAStreaming",
  "inputType": "object",
  "inputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ],
  "hasAsyncIterator": false
}
[2025-11-20T03:32:15.630Z] [DEBUG] [PERPLEXITY_STREAMING] Function entry point reached
DATA: {
  "inputType": "object",
  "inputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ],
  "userQuestionLength": 11,
  "enableStreaming": true
}
[2025-11-20T03:32:15.642Z] [DEBUG] [PERPLEXITY_STREAMING] Getting Perplexity client
[2025-11-20T03:32:15.671Z] [DEBUG] [PERPLEXITY_STREAMING] Client obtained
DATA: {
  "clientType": "object",
  "clientConstructor": "PerplexityClient",
  "hasStreamingMethod": true
}
[2025-11-20T03:32:15.675Z] [DEBUG] [PERPLEXITY_STREAMING] Calling client.streamingCompletionRequest
DATA: {
  "processedInputType": "object",
  "processedInputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ]
}
[2025-11-20T03:32:15.684Z] [DEBUG] [PERPLEXITY_STREAMING] Stream generator created
DATA: {
  "generatorType": "object",
  "generatorConstructor": "",
  "hasAsyncIterator": true
}
[2025-11-20T03:32:15.715Z] [DEBUG] [PERPLEXITY_STREAMING] Starting for-await loop on: client.streamingCompletionRequest
DATA: {
  "iterableSource": "client.streamingCompletionRequest",
  "iterableType": "object",
  "hasAsyncIterator": true,
  "hasIterator": false,
  "constructorName": ""
}
[2025-11-20T03:32:15.722Z] [DEBUG] [PERPLEXITY_CLIENT] PerplexityClient.streamingCompletionRequest called
DATA: {
  "inputType": "object",
  "userQuestionLength": 11,
  "enableStreaming": true
}
[2025-11-20T03:32:15.725Z] [DEBUG] [PERPLEXITY_CLIENT] Making HTTP request to Perplexity API (native fetch)
DATA: {
  "endpoint": "https://api.perplexity.ai/chat/completions",
  "requestDataKeys": [
    "model",
    "temperature",
    "max_tokens",
    "stream",
    "reasoning_effort",
    "messages"
  ],
  "model": "sonar-reasoning",
  "stream": true
}
[2025-11-20T03:32:17.326Z] [DEBUG] [PERPLEXITY_CLIENT] Received HTTP response (native fetch)
DATA: {
  "statusCode": 200,
  "statusText": "OK",
  "hasBody": true,
  "contentType": "text/event-stream; charset=utf-8"
}
[2025-11-20T04:08:09.141Z] [DEBUG] [PERPLEXITY_STREAMING] Starting async generator: perplexityRedChamberQAStreaming
DATA: {
  "functionName": "perplexityRedChamberQAStreaming",
  "inputType": "object",
  "inputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ],
  "hasAsyncIterator": false
}
[2025-11-20T04:08:09.169Z] [DEBUG] [PERPLEXITY_STREAMING] Function entry point reached
DATA: {
  "inputType": "object",
  "inputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ],
  "userQuestionLength": 11,
  "enableStreaming": true
}
[2025-11-20T04:08:09.192Z] [DEBUG] [PERPLEXITY_STREAMING] Getting Perplexity client
[2025-11-20T04:08:09.195Z] [DEBUG] [PERPLEXITY_STREAMING] Client obtained
DATA: {
  "clientType": "object",
  "clientConstructor": "PerplexityClient",
  "hasStreamingMethod": true
}
[2025-11-20T04:08:09.197Z] [DEBUG] [PERPLEXITY_STREAMING] Calling client.streamingCompletionRequest
DATA: {
  "processedInputType": "object",
  "processedInputKeys": [
    "userQuestion",
    "modelKey",
    "reasoningEffort",
    "questionContext",
    "enableStreaming",
    "includeDetailedCitations",
    "showThinkingProcess",
    "temperature",
    "maxTokens",
    "selectedText",
    "chapterContext",
    "currentChapter"
  ]
}
[2025-11-20T04:08:09.199Z] [DEBUG] [PERPLEXITY_STREAMING] Stream generator created
DATA: {
  "generatorType": "object",
  "generatorConstructor": "",
  "hasAsyncIterator": true
}
[2025-11-20T04:08:09.204Z] [DEBUG] [PERPLEXITY_STREAMING] Starting for-await loop on: client.streamingCompletionRequest
DATA: {
  "iterableSource": "client.streamingCompletionRequest",
  "iterableType": "object",
  "hasAsyncIterator": true,
  "hasIterator": false,
  "constructorName": ""
}
[2025-11-20T04:08:09.210Z] [DEBUG] [PERPLEXITY_CLIENT] PerplexityClient.streamingCompletionRequest called
DATA: {
  "inputType": "object",
  "userQuestionLength": 11,
  "enableStreaming": true
}
[2025-11-20T04:08:09.213Z] [DEBUG] [PERPLEXITY_CLIENT] Making HTTP request to Perplexity API (native fetch)
DATA: {
  "endpoint": "https://api.perplexity.ai/chat/completions",
  "requestDataKeys": [
    "model",
    "temperature",
    "max_tokens",
    "stream",
    "reasoning_effort",
    "messages"
  ],
  "model": "sonar-reasoning",
  "stream": true
}
[2025-11-20T04:08:10.837Z] [DEBUG] [PERPLEXITY_CLIENT] Received HTTP response (native fetch)
DATA: {
  "statusCode": 200,
  "statusText": "OK",
  "hasBody": true,
  "contentType": "text/event-stream; charset=utf-8"
}
