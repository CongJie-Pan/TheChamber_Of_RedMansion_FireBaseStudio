/**
 * @fileOverview Daily Reading Comprehension Assessment AI Flow
 *
 * This AI flow evaluates user responses to daily morning reading tasks from
 * "Dream of the Red Chamber". It assesses comprehension depth, accuracy, and
 * literary insight to provide meaningful feedback and scores.
 *
 * Key features:
 * - Comprehension assessment (0-100 score)
 * - Keyword matching and semantic analysis
 * - Constructive feedback in Traditional Chinese
 * - Identification of key points covered/missed
 * - Detailed analysis with improvement suggestions
 *
 * Usage: Called by DailyTaskService when users submit morning reading task answers
 *
 * @phase Phase 2.1 - AI Integration & Scoring System
 * @updated Migrated from GenKit/Gemini to OpenAI GPT-5-mini
 */

'use server'; // Required for server-side AI processing

// Import OpenAI client for AI processing
import { getOpenAIClient } from '@/lib/openai-client';
// Import Zod for schema validation and type inference
import { z } from 'zod';

/**
 * Input schema for reading comprehension assessment
 * æ™¨è®€ç†è§£è©•ä¼°çš„è¼¸å…¥çµæ§‹
 */
const ReadingComprehensionInputSchema = z.object({
  passage: z.string().describe('The text passage from Red Mansion that the user read. Provides context for evaluating the answer quality.'),
  question: z.string().describe('The comprehension question asked to the user. Used to determine if the answer is on-topic and complete.'),
  userAnswer: z.string().describe('The user\'s written response to the comprehension question. This will be evaluated for accuracy, depth, and insight.'),
  expectedKeywords: z.array(z.string()).describe('Key concepts or terms that should appear in a complete answer. Used to assess coverage of important points.'),
  difficulty: z.enum(['easy', 'medium', 'hard']).describe('The difficulty level of the task. Affects scoring criteria and feedback tone.'),
});

/**
 * TypeScript type inferred from the input schema
 * å¾è¼¸å…¥çµæ§‹æ¨æ–·çš„ TypeScript é¡å‹
 */
export type ReadingComprehensionInput = z.infer<typeof ReadingComprehensionInputSchema>;

/**
 * Output schema for reading comprehension assessment results
 * æ™¨è®€ç†è§£è©•ä¼°çµæœçš„è¼¸å‡ºçµæ§‹
 */
const ReadingComprehensionOutputSchema = z.object({
  score: z.number().min(0).max(100).describe('Overall comprehension score from 0-100. Based on relevance, accuracy, completeness, depth, and keyword coverage. Irrelevant answers should score 0-20.'),
  isRelevant: z.boolean().describe('Whether the answer is relevant to the question and passage. False if the answer is completely unrelated content (e.g., news articles, advertisements, other novels).'),
  feedback: z.string().describe('Constructive feedback in Traditional Chinese (ç¹é«”ä¸­æ–‡). Highlights strengths and areas for improvement. For irrelevant answers, clearly indicate the issue and encourage genuine effort.'),
  keyPointsCovered: z.array(z.string()).describe('List of key points or keywords that the user successfully addressed in their answer.'),
  keyPointsMissed: z.array(z.string()).describe('List of important points or keywords that the user did not mention. Used to guide improvement.'),
  detailedAnalysis: z.string().describe('Detailed analysis of the answer quality in Markdown format. For irrelevant answers, explain why it was deemed irrelevant. Use Traditional Chinese (ç¹é«”ä¸­æ–‡).'),
});

/**
 * TypeScript type inferred from the output schema
 * å¾è¼¸å‡ºçµæ§‹æ¨æ–·çš„ TypeScript é¡å‹
 */
export type ReadingComprehensionOutput = z.infer<typeof ReadingComprehensionOutputSchema>;

/**
 * Build the assessment prompt for OpenAI
 * æ§‹å»º OpenAI è©•ä¼°æç¤º
 */
function buildAssessmentPrompt(input: ReadingComprehensionInput): string {
  const keywordsList = input.expectedKeywords.map(k => `- ${k}`).join('\n');

  return `ä½ æ˜¯ä¸€ä½å°ˆæ¥­ä¸”åš´æ ¼çš„ã€Šç´…æ¨“å¤¢ã€‹æ–‡å­¸æ•™å¸«ï¼Œæ­£åœ¨è©•ä¼°å­¸ç”Ÿå°æ—©æ™¨é–±è®€æ®µè½çš„ç†è§£ç¨‹åº¦ã€‚

**é–±è®€æ®µè½ï¼š**
${input.passage}

**å•é¡Œï¼š**
${input.question}

**å­¸ç”Ÿå›ç­”ï¼š**
${input.userAnswer}

**é æœŸé—œéµè©ï¼š**
${keywordsList}

**ä»»å‹™é›£åº¦ï¼š** ${input.difficulty}

---

## ğŸš¨ğŸš¨ğŸš¨ æœ€é‡è¦ï¼šç›¸é—œæ€§æª¢æŸ¥ï¼ˆå¿…é ˆæœ€å…ˆåŸ·è¡Œï¼Œå„ªå…ˆç´šæœ€é«˜ï¼‰ğŸš¨ğŸš¨ğŸš¨

**åœ¨é€²è¡Œä»»ä½•è©•åˆ†å‰ï¼Œä½ å¿…é ˆå…ˆåˆ¤æ–·å­¸ç”Ÿçš„å›ç­”æ˜¯å¦èˆ‡ã€Šç´…æ¨“å¤¢ã€‹å’Œé¡Œç›®ç›¸é—œã€‚é€™æ˜¯æœ€é‡è¦çš„è©•åˆ†æ¨™æº–ï¼**

### ç›´æ¥çµ¦ 20 åˆ†ä¸¦è¨­å®š isRelevant: false çš„æƒ…æ³ï¼ˆç„¡è«–ç­”æ¡ˆå¤šé•·ã€å¯«å¾—å¤šå¥½ï¼‰ï¼š

1. **å®Œå…¨ç„¡é—œçš„å…§å®¹**ï¼š
   - å•†æ¥­æ–°èï¼ˆå¦‚ï¼šå°ç©é›»ã€å¼µå¿ è¬€ã€è‚¡ç¥¨ã€ä¼æ¥­ç®¡ç†ï¼‰
   - ç§‘æŠ€æ–‡ç« ï¼ˆå¦‚ï¼šAIã€æ‰‹æ©Ÿã€é›»è…¦ã€ç¶²è·¯ï¼‰
   - æ”¿æ²»æ–°èï¼ˆå¦‚ï¼šé¸èˆ‰ã€æ”¿åºœã€æ”¿ç­–ï¼‰
   - é«”è‚²æ–°èï¼ˆå¦‚ï¼šçƒè³½ã€é‹å‹•å“¡ï¼‰
   - å…¶ä»–å°èªªæˆ–æ–‡å­¸ä½œå“ï¼ˆéã€Šç´…æ¨“å¤¢ã€‹ï¼‰
   - æ—¥å¸¸ç”Ÿæ´»ç‘£äº‹ï¼ˆèˆ‡é¡Œç›®ç„¡é—œçš„å€‹äººç¶“æ­·ï¼‰
   - å»£å‘Šæ–‡æ¡ˆã€ç”¢å“ä»‹ç´¹

2. **èˆ‡é¡Œç›®æ¯«ç„¡é—œè¯**ï¼š
   - ç­”æ¡ˆå…§å®¹å®Œå…¨æ²’æœ‰æåˆ°é¡Œç›®ä¸­çš„äººç‰©ã€æƒ…ç¯€ã€æˆ–æ¦‚å¿µ
   - ç­”æ¡ˆæ²’æœ‰å˜—è©¦å›æ‡‰å•é¡Œ
   - æ˜é¡¯æ˜¯è¤‡è£½è²¼ä¸Šçš„ç„¡é—œæ–‡å­—

3. **ç„¡æ„ç¾©å…§å®¹**ï¼š
   - èƒ¡è¨€äº‚èªæˆ–ç„¡æ„ç¾©çš„æ–‡å­—çµ„åˆ
   - é‡è¤‡çš„å­—è©æˆ–ç¬¦è™Ÿ

### åˆ¤æ–·æµç¨‹ï¼š
1. å…ˆå•ï¼šå›ç­”å…§å®¹æ˜¯å¦èˆ‡ã€Šç´…æ¨“å¤¢ã€‹é€™éƒ¨å°èªªæœ‰é—œï¼Ÿ
2. å†å•ï¼šå›ç­”æ˜¯å¦å˜—è©¦å›æ‡‰æœ¬é¡Œçš„å•é¡Œï¼Ÿ
3. å¦‚æœå…©è€…çš†ã€Œå¦ã€â†’ ç›´æ¥çµ¦ 20 åˆ†ï¼ŒisRelevant è¨­ç‚º false

### âš ï¸ é‡è¦ï¼šå°æ–¼ç„¡é—œå…§å®¹çš„å›æ‡‰æ–¹å¼
- **ä¸è¦åˆ†æç„¡é—œå…§å®¹**ï¼šä¸è¦è©¦åœ–å¾ç„¡é—œå…§å®¹ä¸­æ‰¾å‡ºä»»ä½•èˆ‡ã€Šç´…æ¨“å¤¢ã€‹çš„é—œè¯
- **feedback ä¿æŒç°¡çŸ­**ï¼šåªéœ€èªªæ˜ã€Œå›ç­”æœªç¬¦åˆé¡Œæ„ã€
- **ä¸è¦çµ¦äºˆä»»ä½•é¼“å‹µæ€§è©•èª**ï¼šå°ç„¡é—œå…§å®¹ä¸éœ€è¦å®¢æ°£

---

## æ­£å¸¸è©•åˆ†æ¨™æº–ï¼ˆåƒ…ç•¶å›ç­”èˆ‡é¡Œç›®ç›¸é—œæ™‚ä½¿ç”¨ï¼‰

1. **æº–ç¢ºæ€§ (30%)**: å›ç­”æ˜¯å¦æ­£ç¢ºç†è§£äº†æ–‡æœ¬å…§å®¹ï¼Œæ²’æœ‰æ˜é¡¯éŒ¯èª¤
2. **å®Œæ•´æ€§ (25%)**: æ˜¯å¦æ¶µè“‹äº†é æœŸçš„é—œéµè©å’Œé‡é»
3. **æ·±åº¦ (25%)**: æ˜¯å¦æœ‰æ·±å…¥çš„åˆ†æå’Œè¦‹è§£ï¼Œè€Œéåƒ…åœç•™åœ¨è¡¨é¢
4. **æ–‡å­¸ç´ é¤Š (20%)**: æ˜¯å¦å±•ç¾å°ã€Šç´…æ¨“å¤¢ã€‹æ–‡å­¸ç‰¹è‰²çš„ç†è§£

**è©•åˆ†æŒ‡å—ï¼š**
- **ç°¡å–®é›£åº¦ (easy)**: åªè¦å›ç­”åŸºæœ¬æ­£ç¢ºä¸”æåˆ° 1-2 å€‹é—œéµè©ï¼Œå³å¯çµ¦äºˆ 70+ åˆ†
- **ä¸­ç­‰é›£åº¦ (medium)**: éœ€è¦å›ç­”æº–ç¢ºã€æ¶µè“‹å¤šæ•¸é—œéµè©ã€æœ‰ä¸€å®šåˆ†ææ·±åº¦ï¼Œæ‰èƒ½çµ¦äºˆ 70+ åˆ†
- **å›°é›£é›£åº¦ (hard)**: éœ€è¦æ·±å…¥åˆ†æã€å…¨é¢æ¶µè“‹é—œéµè©ã€å±•ç¾æ–‡å­¸æ´å¯Ÿï¼Œæ‰èƒ½çµ¦äºˆ 70+ åˆ†

---

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š

**å¦‚æœå›ç­”èˆ‡é¡Œç›®ç›¸é—œ (isRelevant: true)ï¼š**
{
  "score": æ ¹æ“šè©•åˆ†æ¨™æº–çµ¦äºˆçš„åˆ†æ•¸ (0-100),
  "isRelevant": true,
  "feedback": "é¼“å‹µæ€§çš„ç°¡çŸ­åé¥‹ (50-100å­—)ï¼ŒæŒ‡å‡ºå„ªé»å’Œæ”¹é€²æ–¹å‘",
  "keyPointsCovered": ["å­¸ç”ŸæˆåŠŸæåˆ°çš„é—œéµè©1", "é—œéµè©2"],
  "keyPointsMissed": ["å­¸ç”Ÿæœªæåˆ°ä½†æ‡‰è©²åŒ…å«çš„é—œéµè©1", "é—œéµè©2"],
  "detailedAnalysis": "200-300å­—çš„è©³ç´°è©•æï¼Œä½¿ç”¨ Markdown æ ¼å¼"
}

**å¦‚æœå›ç­”èˆ‡é¡Œç›®ç„¡é—œ (isRelevant: false)ï¼š**
{
  "score": 20,
  "isRelevant": false,
  "feedback": "æ‚¨çš„å›ç­”æœªç¬¦åˆé¡Œæ„ï¼Œå…§å®¹èˆ‡ã€Šç´…æ¨“å¤¢ã€‹åŠæœ¬é¡Œç„¡é—œã€‚",
  "keyPointsCovered": [],
  "keyPointsMissed": ["æ‰€æœ‰é æœŸé—œéµè©"],
  "detailedAnalysis": "æ‚¨æäº¤çš„å…§å®¹èˆ‡æœ¬é¡Œè¦æ±‚ç„¡é—œã€‚è«‹ä»”ç´°é–±è®€é¡Œç›®ï¼Œæä¾›èˆ‡ã€Šç´…æ¨“å¤¢ã€‹ç›¸é—œçš„å›ç­”ã€‚"
}

è«‹ä»¥ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚å°æ–¼ç›¸é—œå…§å®¹èªæ°£å‹å–„ï¼Œå°æ–¼ç„¡é—œå…§å®¹å‰‡ç›´æ¥æŒ‡å‡ºå•é¡Œã€‚ç¢ºä¿å›è¦†æ ¼å¼ç‚ºæœ‰æ•ˆçš„ JSONã€‚`;
}

/**
 * Parse OpenAI response and validate schema
 * è§£æ OpenAI å›æ‡‰ä¸¦é©—è­‰çµæ§‹
 */
function parseAssessmentResponse(responseText: string, input: ReadingComprehensionInput): ReadingComprehensionOutput {
  try {
    // Try to parse JSON response
    const parsed = JSON.parse(responseText);

    // Validate and sanitize isRelevant (default to true if not provided)
    const isRelevant = typeof parsed.isRelevant === 'boolean'
      ? parsed.isRelevant
      : true;

    // Validate and sanitize score
    // If answer is irrelevant, cap score at 20
    let score = typeof parsed.score === 'number'
      ? Math.max(0, Math.min(100, Math.round(parsed.score)))
      : 50;

    // Enforce low score for irrelevant answers
    if (!isRelevant && score > 20) {
      console.log(`âš ï¸ [AI Assessment] Capping score from ${score} to 20 due to irrelevant content`);
      score = 20;
    }

    // Validate and sanitize other fields
    const feedback = typeof parsed.feedback === 'string' && parsed.feedback.length > 0
      ? parsed.feedback
      : isRelevant
        ? 'æ„Ÿè¬æ‚¨çš„å›ç­”ï¼Œè«‹ç¹¼çºŒåŠªåŠ›ï¼'
        : 'æ‚¨çš„å›ç­”ä¼¼ä¹èˆ‡é¡Œç›®ç„¡é—œï¼Œè«‹ä»”ç´°é–±è®€é¡Œç›®å¾Œé‡æ–°ä½œç­”ã€‚';

    const keyPointsCovered = Array.isArray(parsed.keyPointsCovered)
      ? parsed.keyPointsCovered.filter((k: any): k is string => typeof k === 'string')
      : [];

    const keyPointsMissed = Array.isArray(parsed.keyPointsMissed)
      ? parsed.keyPointsMissed.filter((k: any): k is string => typeof k === 'string')
      : input.expectedKeywords;

    const detailedAnalysis = typeof parsed.detailedAnalysis === 'string' && parsed.detailedAnalysis.length > 0
      ? parsed.detailedAnalysis
      : isRelevant
        ? '# è©•ä¼°åˆ†æ\n\næ‚¨çš„å›ç­”å·²æ”¶åˆ°ï¼Œè«‹ç¹¼çºŒå­¸ç¿’ã€‚'
        : '# è©•ä¼°åˆ†æ\n\næ‚¨çš„å›ç­”å…§å®¹èˆ‡é¡Œç›®ç„¡é—œã€‚è«‹ä»”ç´°é–±è®€é–±è®€æ®µè½å’Œå•é¡Œï¼Œç„¶å¾Œæä¾›èˆ‡ã€Šç´…æ¨“å¤¢ã€‹ç›¸é—œçš„ç­”æ¡ˆã€‚';

    return {
      score,
      isRelevant,
      feedback,
      keyPointsCovered,
      keyPointsMissed,
      detailedAnalysis,
    };
  } catch (error) {
    // If JSON parsing fails, return fallback response
    console.error('Failed to parse OpenAI response as JSON:', error);
    throw new Error('AI response parsing failed');
  }
}

/**
 * Main exported function for reading comprehension assessment
 * æ™¨è®€ç†è§£è©•ä¼°çš„ä¸»è¦å°å‡ºå‡½æ•¸
 *
 * @param input - Reading comprehension task data including passage, question, and user answer
 * @returns Assessment results with score, feedback, and detailed analysis
 */
export async function assessReadingComprehension(
  input: ReadingComprehensionInput
): Promise<ReadingComprehensionOutput> {
  try {
    // Get OpenAI client
    const openai = getOpenAIClient();

    // Build assessment prompt
    const prompt = buildAssessmentPrompt(input);

    // Call OpenAI API with gpt-5-mini
    const completion = await openai.chat.completions.create({
      model: 'gpt-5-mini',
      messages: [
        {
          role: 'system',
          content: 'ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ã€Šç´…æ¨“å¤¢ã€‹æ–‡å­¸æ•™å¸«ï¼Œæ“…é•·è©•ä¼°å­¸ç”Ÿçš„é–±è®€ç†è§£èƒ½åŠ›ã€‚è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ã€‚',
        },
        {
          role: 'user',
          content: prompt,
        },
      ],
      temperature: 0.7,
      max_tokens: 1500,
      response_format: { type: 'json_object' }, // Request JSON response
    });

    // Extract response content
    const responseText = completion.choices[0]?.message?.content;

    if (!responseText) {
      throw new Error('OpenAI returned empty response');
    }

    // Parse and validate response
    return parseAssessmentResponse(responseText, input);

  } catch (error) {
    // Log error only in non-test environments
    if (process.env.NODE_ENV !== 'test') {
      console.error('Error in assessReadingComprehension:', error);
    }

    // Return fallback assessment
    return {
      score: 50,
      isRelevant: true, // Assume relevant when AI is unavailable
      feedback: 'å¾ˆæŠ±æ­‰ï¼ŒAI è©•åˆ†ç³»çµ±æš«æ™‚ç„¡æ³•ä½¿ç”¨ã€‚æ‚¨çš„å›ç­”å·²è¨˜éŒ„ï¼Œæˆ‘å€‘æœƒç›¡å¿«äººå·¥å¯©æ ¸ã€‚',
      keyPointsCovered: [],
      keyPointsMissed: input.expectedKeywords,
      detailedAnalysis: '## ç³»çµ±æç¤º\n\nè©•åˆ†ç³»çµ±æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œè«‹ç¨å¾ŒæŸ¥çœ‹è©³ç´°åé¥‹ã€‚',
    };
  }
}
